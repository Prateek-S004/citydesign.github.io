<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Course Learning Reflections</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <h1>Course Learning Reflections</h1>
    <div class="content">
        <section id="problems-in-nature">
            <h3>1. Problems in Nature</h3>
            <ul>
                <li><strong>Iteration:</strong> Water droplets falling repeatedly in a stream, patterns formed by repetitive waves.</li>
                <li><strong>Recursion:</strong> Branching of trees or rivers, where the structure repeats at smaller scales.</li>
                <li><strong>Backtracking:</strong> Ants searching for food, solving mazes.</li>
            </ul>
        </section>
    </div>
    
    <div class="content">
        <section id="space-time-efficiency">
            <h3>2. Space and Time Efficiency</h3>
            <div class="section-title">Definitions</div>
            <ul>
                <li><strong>Space Efficiency:</strong> Extra memory (space) used during execution.</li>
                <li><strong>Time Efficiency:</strong> How fast a program completes its execution.</li>
            </ul>
            <div class="section-title">Importance</div>
            <p>Handles larger inputs without excessive resources, saving on computational costs.</p>
            <div class="section-title">Classes of Problems</div>
            <ul>
                <li>Decomposition</li>
                <li>Pattern Recognition</li>
                <li>Abstraction</li>
                <li>Brave and Cautious Travel</li>
                <li>Pruning</li>
                <li>Lazy Propagation Evaluation</li>
                <li>Sliding Window</li>
                <li>Level Order Traversal</li>
                <li>Hierarchical Data</li>
                <li>Edge Relaxation</li>
                <li>Balancing and Rotations</li>
                <li>Kleene Closure</li>
                <li>Pre-Computing</li>
                <li>Parental Dominance</li>
                <li>Prefix and Suffix</li>
                <li>Partitioning</li>
                <li>Bit Manipulations</li>
                <li>Memoization</li>
                <li>Invariants</li>
                <li>Shortest Path Trees</li>
            </ul>
            <div class="section-title">Order of Growth</div>
            <ul>
                <li>O(n!): Grows explosively (brute-force).</li>
                <li>O(3^n): Exponential growth with base 3 (combinatorial problems).</li>
                <li>O(2^n): Exponential growth with base 2 (recursive problems).</li>
                <li>O(n^3): Polynomial growth (cubic-time algorithms).</li>
                <li>O(n^2): Quadratic growth (Bubble Sort).</li>
                <li>O(nlogn): Sub-quadratic growth (divide-and-conquer algorithms).</li>
                <li>O(n): Linear growth (single-loop algorithms).</li>
                <li>O(root(n)): Sub-linear growth (e.g., finding factors).</li>
                <li>O(logn): Logarithmic growth (divide-and-conquer strategies).</li>
            </ul>
        </section>
    </div>
        
    <div class="content">
        <section id="tree-data-structures">
            <h3>3. Tree Data Structures</h3>
            <ul>
                <li><strong>Tree:</strong> Simple and memory efficient.</li>
                <li><strong>Binary Search Tree (BST):</strong> Used for sorting, may create skewness.</li>
                <li><strong>2-3 Tree:</strong> Reduces skewness by storing more than one element per node.</li>
                <li><strong>AVL Tree:</strong> Balances through rotations, but may become complex.</li>
                <li><strong>Red-Black Tree:</strong> Reduces rotations.</li>
                <li><strong>Heap:</strong> Priority queues, dynamic memory allocation.</li>
                <li><strong>Trie:</strong> Optimized for strings, where paths represent characters.</li>
            </ul>
        </section>
    </div>

    <div class="content">
        <section id="array-query-algorithms">
            <h3>4. Array Query Algorithms</h3>
            <p>Efficiently answer questions about an array, crucial for performance-critical systems.</p>
            <div class="section-title">Applications</div>
            <p>Used in competitive programming and real-world systems for performance-critical queries on large datasets.</p>
            <div class="section-title">Principles</div>
            <p>Divide and conquer, preprocessing.</p>
            <div class="section-title">Examples</div>
            <ul>
                <li><strong>Segment Trees:</strong> O(logn) complexity for range queries and updates.</li>
                <li><strong>Fenwick Trees:</strong> O(logn) complexity with lower memory overhead.</li>
                <li><strong>Sparse Table:</strong> O(1) query time after O(nlogn) preprocessing.</li>
            </ul>
        </section>
    </div>

    <div class="content">
        <section id="trees-vs-graphs">
            <h3>5. Trees vs. Graphs</h3>
            <div class="section-title">Traversal</div>
            <ul>
                <li><strong>Trees:</strong> Pre-order, In-order, Post-order.</li>
                <li><strong>Graphs:</strong> DFS, BFS.</li>
            </ul>
            <div class="section-title">Key Differences</div>
            <ul>
                <li><strong>Trees:</strong> Hierarchical structure, no cycles.</li>
                <li><strong>Graphs:</strong> Generalized structure, can have cycles.</li>
            </ul>
            <div class="section-title">Applications</div>
            <ul>
                <li><strong>Trees:</strong> File systems, organizational charts, decision trees.</li>
                <li><strong>Graphs:</strong> Social networks, road maps, network analysis.</li>
            </ul>
        </section>
    </div>

    <div class="content">
        <section id="sorting-searching">
            <h3>6. Sorting and Searching Algorithms</h3>
            <div class="section-title">Sorting Algorithms</div>
            <ul>
                <li><strong>Bubble Sort:</strong> Repeatedly swaps adjacent elements if they are in the wrong order. <br>
                    <strong>Complexity:</strong> O(n<sup>2</sup>) in the worst case.
                </li>
                <li><strong>Selection Sort:</strong> Finds the smallest (or largest) element in the unsorted part and places it in its correct position. <br>
                    <strong>Complexity:</strong> O(n<sup>2</sup>).
                </li>
                <li><strong>Insertion Sort:</strong> Builds the sorted array one element at a time by inserting elements into their correct positions. <br>
                    <strong>Complexity:</strong> O(n<sup>2</sup>) worst case, O(n) best case.
                </li>
                <li><strong>Merge Sort:</strong> A divide-and-conquer algorithm that splits the array into halves, sorts them, and merges them back. <br>
                    <strong>Complexity:</strong> O(nlogn).
                </li>
                <li><strong>Quick Sort:</strong> Partitions the array around a pivot, placing smaller elements on one side and larger on the other, and sorts recursively. <br>
                    <strong>Complexity:</strong> O(n<sup>2</sup>) worst case, O(nlogn) average case.
                </li>
                <li><strong>Heap Sort:</strong> Converts the array into a max-heap or min-heap and extracts elements one by one. <br>
                    <strong>Complexity:</strong> O(nlogn).
                </li>
            </ul>
    
            <div class="section-title">Searching Algorithms (Strings)</div>
            <ul>
                <li><strong>Boyer-Moore Algorithm:</strong> Skips portions of the text by leveraging mismatches, making it faster for large patterns. <br>
                    <strong>Complexity:</strong> O(nm) worst case, O(n) best case.
                </li>
                <li><strong>Knuth-Morris-Pratt (KMP) Algorithm:</strong> Uses a prefix-suffix table to avoid rechecking characters. <br>
                    <strong>Complexity:</strong> O(n + m).
                </li>
                <li><strong>Rabin-Karp Algorithm:</strong> Uses a rolling hash to compare substrings with the pattern. <br>
                    <strong>Complexity:</strong> O(nm) worst case, O(n + m) average case.
                </li>
            </ul>
    
            <div class="section-title">Searching Algorithms (Graphs)</div>
            <ul>
                <li><strong>Dijkstra's Algorithm:</strong> Finds the shortest path from a source node to all others using edge weights. <br>
                    <strong>Complexity:</strong> O(V<sup>2</sup>) with adjacency matrix, O(E + VlogV) with priority queue.
                </li>
                <li><strong>Kruskal's Algorithm:</strong> Selects edges in ascending weight order, ensuring no cycles form. <br>
                    <strong>Complexity:</strong> O(E logE).
                </li>
                <li><strong>Prim's Algorithm:</strong> Grows the spanning tree by adding the shortest edge from the tree to a non-tree vertex. <br>
                    <strong>Complexity:</strong> O(V<sup>2</sup>) with adjacency matrix, O(E + VlogV) with priority queue.
                </li>
                <li><strong>Floyd-Warshall Algorithm:</strong> Computes shortest paths between all pairs of nodes using dynamic programming. <br>
                    <strong>Complexity:</strong> O(V<sup>3</sup>).
                </li>
                <li><strong>Warshall's Algorithm:</strong> Determines whether there is a path between each pair of vertices. <br>
                    <strong>Complexity:</strong> O(V<sup>3</sup>).
                </li>
            </ul>
        </section>
    </div>
</body>
</html>
    
